cat("Running SVM tuning and validation with RBF kernel\n")

#cat("Creating dataframe for SVM\n")
#data_for_svm<-thickness_over_17_pca_train$x[,1:n_pcs] 
#where n_pcs hold number of PCs that explain >1% of variance)
#data_for_svm<-as.data.frame(data_for_svm)
#data_for_svm<-cbind(dx_train,data_for_svm)

cat("Creating Cost vector (from 2^-14 to 2^10)\n")
cost<-length(25)
cost<-2^seq(-14, 10, by=0.5)

cat("Creating gamma vector (from 2^-14 to 2^10)\n")
gamma<-length(25)
gamma<-2^seq(-14, 10, by=0.5)

cat("Tuning SVM\n")
tuned_svm<-tune.svm(data_for_svm[,-1],data_for_svm[,1],cost=cost,gamma=gamma)

#Best params stored in tuned_svm$best.parameters
#Best model stored in tuned_svm$best.model

cat("Best accuracy is:\n")
tuned_svm$best.performance #This is LOWEST ERROR (ie. 1-accuracy)

cat("Predicting classes for validation\n")
svm.pred<-predict(tuned_svm$best.model,pred.data[,1:n_pcs])

cat("Final accuracies\n")
results<-table(svm.pred,dx[-train_indices])

sens<-results[4]/(results[3]+results[4])

spec<-results[1]/(results[1]+results[2])

acc<-(results[1]+results[4])/(results[1]+results[2]+results[3]+results[4])

#what should do is train another model with optimal cost and gamma using 10-fold x-val, then report tot.accuracy -> tune.svm actually does 10-fold cross-validation on each cost/gamma combination (see tuned_svm$sampling. Hence the accuracy stored in tuned_svm$best.performance represents the mean accuracy across 10 rounds of cross-validation using the best cost and gamma

train.acc<-(1-tuned_svm$best.performance)
